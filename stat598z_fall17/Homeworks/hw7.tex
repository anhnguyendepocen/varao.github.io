\documentclass[10pt]{article}
\usepackage{fullpage}
\usepackage[shortlabels]{enumitem}
\usepackage{amsfonts}
\input{../base_style.sty}

       \hypersetup{
         colorlinks,
         urlcolor = red,
%         citecolor=green,
         linkcolor=black
       }



\def\cM{\mathcal{M}}
\def\cMI{\mathcal{S}}
\title{Stats 598z: Homework 7}
\author{Due before midnight Sunday, Apr 30}
%.\\ All plots should have labelled axes and titles.\\
%}
\date{}
\begin{document}
\maketitle
\textbf{Important:\\~\\
  \R\ code, tables and figures should be part of a single .pdf or .html files from {\tt R Markdown} and {\tt knitr}. 
See the class reading lists for a short tutorial.\\
Include \R\ commands for all output unless explicitly told not to.\\
If you collaborated with anyone else, mention their names and the nature of the collaboration}

%\section{Problem 1: k-nearest neighbours \hfill[100pts]}

% \begin{enumerate}[(a)]
%   \item Reduce all state names to lower case
%   \item Identify all states whose names start and end with a vowel. Show the murder counts for these.
%   \item Identify all states whose names contain a letter repeated twice in succession
%   \item Identify all states whose names contain a letter repeated twice (not necessarily in succession)
%   \item Identify all states whose names contain two words
% \end{enumerate}

\section{The law of large numbers \hfill[20pts]}
This assignment uses \texttt{ggvis} with reactive programming, see
the last slide of lecture 20. Create a dataframe with three columns: 
    \texttt{(indx,value,running\_mean)}.
    Initially all are initialized to 0. Write code to 
\begin{enumerate}[(a)]
  \item 
      Every 200ms, add a new row to the data-frame, with
  \texttt{indx} increasing by 1, \texttt{value} assigned a random value from the
    normal distribution, and \texttt{running\_mean} giving the mean of all
    \texttt{value}s so far. 
  Include a \texttt{ggvis} interface,
    so that you display a video of the evolution of the \texttt{running\_mean}
    with time.     \hfill[15pts]
  \item Change the \texttt{ggvis} part of the code, so it rather that
    updating the trajectory of \texttt{running\_mean}, it plots the histogram
    of \texttt{value} every 200ms. \hfill[10pts]
\end{enumerate}
For both parts, look at the documentation of ggvis to keep the x- and y-
limits clamped over some suitable range (hint: see \url{http://stackoverflow.com/questions/24491783/ggvis-density-plot-xlim-xlab})

\section{Monte Carlo sampling \hfill[25pts]}
    \begin{itemize}
      \item Consider two points $p_1=(x_1,y_1)$ and $p_2 = (x_2,y_2)$. The
        coordinates of $p_1$ are distributed as Gaussian with mean $0$, and
        of $p_2$, as Gaussian with mean $1$. You want to calculate the average
        length of the line-segment connecting two such points. Get a
        Monte Carlo estimate of this using $5000$ samples. Recall the procedure:
        sample $5000$ instances of $p_1$ and $p_2$ from their distributions, 
        calculate the length of
        the line joining them for each instance and then calculate the average.
        \hfill[15pts]
      \item Repeat the above procedure $1000$ times, getting a random estimate 
        each time. Plot a histogram of these values using {\tt ggvis}. Include
        a tooltip that give the value in bin of the histogram you're pointing
        at, which is highlighted in red (see the slides from Lecture 20).
        \hfill[10pts]
    \end{itemize}

\section{Importance sampling \hfill[50pts]}

\begin{enumerate}[(a)]
  \item What is the mean and standard deviation of the sum of $100$ fair
    dice? \hfill[5]
  \item Write a few lines of \R\ to simulate the output of $100$ fair die
    a thousand times.  Plot the histogram of the sum, and show that the
    mean and standard deviation match the previous question. \hfill[5]
  \item Use the {\tt pnorm} function to calculate the log-probability a
    Gaussian with this mean and standard deviation exceeds $450$. \hfill[5]
  \item
    What fraction of your outcomes had a sum exceeding $450$? This is your Monte Carlo estimate.
     \hfill[5]
  \item Now, simulate $100$ biased dice, with each die having probability
    proportional to $i$ of showing side $i$. Do this $1000$ times.
    Plot the histogram of the sum of these values. How many times does
    the sum exceed $450$? \hfill[5]
  \item Calculate the log-probability (under the biased dice) of each of 
    the $1000$ outcomes.
    Do not use for-loops.  
    (note that the log-probability of a 100-dice outcome is the 
    sum of the log-probabilities of the outputs of each of the $100$ dice
    that constitute it).
    \hfill[10]
  \item What is the log-probability of any outcome under the fair dice? \hfill[5]
  \item Given the two $1000$-vectors of log-probabilities of the $1000$ outputs
    under the biased and fair dice, obtain an importance sampling
    estimate of the log-probability that the sum of $100$ dice exceeds
    $450$ \hfill[10]
\end{enumerate}


% \section{Problem 2: Metropolis-Hastings \hfill  [50pts]} 
% \begin{enumerate}
%   \item We saw the Rosenbrock density, whose log-probability is given
%     (upto a normalization constant) by $\log p(x) = -(a-x)^2-b(y-x^2)^2$.
%     Write a function {\tt rosenbrock} that takes in $4$ inputs, {\tt x,y
%     a,b} and returns the unnormalized log-probability. Set {\tt a} and 
%     {\tt b} to have default values $0.3$ and $3$ respectively.
%     \hfill[5]
%   \item Use the {\tt geom\_tile} aesthetic to plot this density as in
%     lecture 24. For this, consider a 2-d grid with $x$ taking values
%     from $-2$ to $2$, and $y$ from $-1$ to $5$ in steps of $0.1$.
%     Next, using the {\tt rep} function create a data frame where the elements of the first two columns
%     cover every $(x,y)$ pair on the grid, and the last column contains
%     {\tt rosenbrock} evaluated at this point.  \hfill[10]
%   \item 
%     %Now, we will use Metropolis-Hastings to calculate the mean
%     %and covariance matrix of this function.
%     Write a function {\tt mh\_sampler} to run Metropolis-Hastings
%     on any target log-probability density. {\tt mh\_sampler} takes
%     as input $5$ inputs, {\tt target, init, burn, num\_smpl}. The
%     first argument {\tt target} is another function that returns the
%     log-probability at any location (we will use {\tt rosenbrock} for this
%     when we call {\tt mh\_sampler}). {\tt init} gives the initialization
%     of the Markov chain, while {\tt burn, num\_smpl} give the number of 
%     burn-in and MCMC samples respectively. {\tt scl} give the standard
%     deviation of the MH proposals.

%     The overall structure of the algorithm involves first creating a
%     vector with $2$ columns and {\tt burn + num\_sample} rows. The first
%     row is set to {\tt init}. At each iteration, we propose a new value
%     from a 2-d Gaussian with mean equal to the current value and standard
%     deviation equal to {\tt scale}. The proposal is accepted with the
%     MH-acceptance probability, else is old sample is used.
%      \hfill[25]
%   \item Run your MH algorithm on the Rosenbrock density, using a burn-in
%     of $1000$ samples and $10000$ samples overall. Set the proposal
%     standard deviation equal to $1$. Use the $10000$ MCMC samples to calculate
%     the mean and covariance matrix of the Rosenbrock density. \hfill[10]
% \end{enumerate}
\end{document}
